After the Covid pandemic made it difficult for high school students to take the SAT and ACT, dozens of selective colleges dropped their requirement that applicants do so. Colleges described the move as temporary, but nearly all have since stuck to a test-optional policy. It reflects a backlash against standardized tests that began long before the pandemic, and many people have hailed the change as a victory for equity in higher education.

Now, though, a growing number of experts and university administrators wonder whether the switch has been a mistake. Research has increasingly shown that standardized test scores contain real information, helping to predict college grades, chances of graduation and post-college success. Test scores are more reliable than high school grades, partly because of grade inflation in recent years.

Without test scores, admissions officers sometimes have a hard time distinguishing between applicants who are likely to do well at elite colleges and those who are likely to struggle. Researchers who have studied the issue say that test scores can be particularly helpful in identifying lower-income students and underrepresented minorities who will thrive. These students do not score as high on average as students from affluent communities or white and Asian students. But a solid score for a student from a less privileged background is often a sign of enormous potential.

“Standardized test scores are a much better predictor of academic success than high school grades,” Christina Paxson, the president of Brown University, recently wrote. Stuart Schmill — the dean of admissions at M.I.T., one of the few schools to have reinstated its test requirement — told me, “Just getting straight A’s is not enough information for us to know whether the students are going to succeed or not.”