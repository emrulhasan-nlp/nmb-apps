Much of the current discourse about artificial intelligence sucks. A.I. is one of those subjects that seem to appear out of nowhere, blotting out everything else — like the sun rising over the desert — and a mixture of ludicrous hype and vacuous panic has rushed in to shade the blinding dazzle. A.I. is going to transform every industry, or it’s going to end the world, or both, and you need to know which now. Meanwhile, accurate answers to basic questions — What even is it? How does it work? Where did it come from? Where is it going? — tend to be tucked away in dry technical language that borders on the incomprehensible.

Before the launch of ChatGPT, a little more than a year ago, it was difficult to get readers to care about A.I. Sam Altman, the chief executive of OpenAI, would tell anybody who would listen that A.I. needed regulation, but few in power were listening. Editors sniffed. Readers yawned.

After the launch of ChatGPT, everybody had an opinion, and nobody knew what they were talking about. The novelty and the urgency provoked the usual grift that accompanies any glut of public ignorance. The movies, with their predilection for wild visions of the artificial intelligence future (A.I. will start nuclear war, enslave humanity or teach us the nature of love), didn’t help. And, after a decade during which Silicon Valley has demonstrated that it lacks any sense of social responsibility, it has become impossible to trust the creators of A.I. Then there is the confounding nature of the technology itself, which often eludes the understanding even of the people who invented it. It’s amazing that anything good about A.I. ever gets written.